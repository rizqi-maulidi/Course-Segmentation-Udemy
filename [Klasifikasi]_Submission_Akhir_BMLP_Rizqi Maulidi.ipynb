{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKADPWcFKlj3"
      },
      "source": [
        "# **1. Import Library**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgA3ERnVn84N"
      },
      "source": [
        "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "BlmvjLY9M4Yj"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3YIEnAFKrKL"
      },
      "source": [
        "# **2. Memuat Dataset dari Hasil Clustering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey3ItwTen_7E"
      },
      "source": [
        "Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "GHCGNTyrM5fS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13608 entries, 0 to 13607\n",
            "Data columns (total 9 columns):\n",
            " #   Column                        Non-Null Count  Dtype  \n",
            "---  ------                        --------------  -----  \n",
            " 0   is_paid                       13608 non-null  bool   \n",
            " 1   num_subscribers               13608 non-null  float64\n",
            " 2   avg_rating                    13608 non-null  float64\n",
            " 3   num_reviews                   13608 non-null  float64\n",
            " 4   num_published_lectures        13608 non-null  float64\n",
            " 5   num_published_practice_tests  13608 non-null  float64\n",
            " 6   discount_price__amount        13608 non-null  float64\n",
            " 7   price_detail__amount          13608 non-null  float64\n",
            " 8   cluster                       13608 non-null  int64  \n",
            "dtypes: bool(1), float64(7), int64(1)\n",
            "memory usage: 863.9 KB\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load data\n",
        "df = pd.read_csv('Dataset_clustering.csv')\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkPem5eWL2UP"
      },
      "source": [
        "# **3. Data Splitting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYj1rl_JNI9Y"
      },
      "source": [
        "Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "OubAW-7ONKVj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set shape: X_train=(10886, 8), y_train=(10886,)\n",
            "Test set shape: X_test=(2722, 8), y_test=(2722,)\n"
          ]
        }
      ],
      "source": [
        "# Buat salinan data biar nggak ngubah data asli\n",
        "data = df.copy()\n",
        "\n",
        "# Buat instance MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Pilih semua kolom numerik kecuali kolom target ('cluster')\n",
        "numeric_columns = data.select_dtypes(include=['int64', 'float64']).columns.drop('cluster')\n",
        "\n",
        "# Normalisasi semua kolom numerik\n",
        "data[numeric_columns] = scaler.fit_transform(data[numeric_columns])\n",
        "\n",
        "# Pisahkan fitur (X) dan target (y)\n",
        "X = data.drop(columns=['cluster'])\n",
        "y = data['cluster']\n",
        "\n",
        "# Split data menjadi training dan test set (80:20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tampilkan bentuk set pelatihan dan set uji untuk memastikan split\n",
        "print(f\"Training set shape: X_train={X_train.shape}, y_train={y_train.shape}\")\n",
        "print(f\"Test set shape: X_test={X_test.shape}, y_test={y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVPbB03CMhTT"
      },
      "source": [
        "# **4. Membangun Model Klasifikasi**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ned1pL9zMmBK"
      },
      "source": [
        "## **a. Membangun Model Klasifikasi**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAWzPOE4Nkti"
      },
      "source": [
        "Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.\n",
        "\n",
        "Berikut adalah rekomendasi tahapannya.\n",
        "1. Pilih algoritma klasifikasi yang sesuai, seperti Logistic Regression, Decision Tree, Random Forest, atau K-Nearest Neighbors (KNN).\n",
        "2. Latih model menggunakan data latih."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "4JYxBe87NLDk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model training selesai.\n"
          ]
        }
      ],
      "source": [
        "# Bagian 1: Pelatihan Model\n",
        "# Definisikan dan latih setiap model secara terpisah\n",
        "knn = KNeighborsClassifier().fit(X_train, y_train)\n",
        "svm = SVC().fit(X_train, y_train)\n",
        "nb = GaussianNB().fit(X_train, y_train)\n",
        "\n",
        "print(\"Model training selesai.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seYoHNY3XU1y"
      },
      "source": [
        "Tulis narasi atau penjelasan algoritma yang Anda gunakan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ergzChZFEL-O"
      },
      "source": [
        "## **b. Evaluasi Model Klasifikasi**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOm68u-7NpLT"
      },
      "source": [
        "Berikut adalah **rekomendasi** tahapannya.\n",
        "1. Lakukan prediksi menggunakan data uji.\n",
        "2. Hitung metrik evaluasi seperti Accuracy dan F1-Score (Opsional: Precision dan Recall).\n",
        "3. Buat confusion matrix untuk melihat detail prediksi benar dan salah."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "tMq4QAssNLip"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                          Model  Accuracy  Precision    Recall  F1-Score  \\\n",
            "0     K-Nearest Neighbors (KNN)  0.998898   0.998899  0.998898  0.998892   \n",
            "1  Support Vector Machine (SVM)  0.997796   0.997801  0.997796  0.997773   \n",
            "2              Naive Bayes (NB)  0.996326   0.996571  0.996326  0.996386   \n",
            "\n",
            "   Cross-Validation Mean  Cross-Validation Std  \n",
            "0               0.997869              0.004080  \n",
            "1               0.996914              0.005301  \n",
            "2               0.990447              0.003221  \n"
          ]
        }
      ],
      "source": [
        "# Fungsi untuk mengevaluasi model dengan confusion matrix\n",
        "def evaluate_model(model, X_test, y_test):\n",
        "    y_pred = model.predict(X_test)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    \n",
        "    # Pastikan confusion matrix memiliki ukuran yang sesuai untuk pembacaan TP, TN, FP, FN\n",
        "    if cm.shape == (2, 2):  # Hanya jika klasifikasi biner\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "    else:\n",
        "        tn, fp, fn, tp = None, None, None, None  # Untuk kasus multi-class\n",
        "\n",
        "    results = {\n",
        "        'Confusion Matrix': cm,\n",
        "        'True Positive (TP)': tp,\n",
        "        'False Positive (FP)': fp,\n",
        "        'False Negative (FN)': fn,\n",
        "        'True Negative (TN)': tn,\n",
        "        'Accuracy': accuracy_score(y_test, y_pred),\n",
        "        'Precision': precision_score(y_test, y_pred, average='weighted'),\n",
        "        'Recall': recall_score(y_test, y_pred, average='weighted'),\n",
        "        'F1-Score': f1_score(y_test, y_pred, average='weighted')\n",
        "    }\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Fungsi untuk evaluasi cross-validation\n",
        "def cross_validate_model(model, X, y, cv=5):\n",
        "    scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy')\n",
        "    return scores.mean(), scores.std()\n",
        "\n",
        "# Simpan model dalam dictionary untuk menghindari kesalahan `eval()`\n",
        "models = {\n",
        "    'K-Nearest Neighbors (KNN)': knn,\n",
        "    'Support Vector Machine (SVM)': svm,\n",
        "    'Naive Bayes (NB)': nb\n",
        "}\n",
        "\n",
        "# Mengevaluasi setiap model\n",
        "results = {name: evaluate_model(model, X_test, y_test) for name, model in models.items()}\n",
        "\n",
        "# Buat DataFrame untuk menyimpan hasil evaluasi\n",
        "summary_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'Cross-Validation Mean', 'Cross-Validation Std'])\n",
        "\n",
        "# Isi DataFrame dengan hasil evaluasi\n",
        "rows = []\n",
        "for model_name, model in models.items():\n",
        "    metrics = results[model_name]\n",
        "    mean_cv, std_cv = cross_validate_model(model, X, y, cv=5)\n",
        "\n",
        "    rows.append({\n",
        "        'Model': model_name,\n",
        "        'Accuracy': metrics['Accuracy'],\n",
        "        'Precision': metrics['Precision'],\n",
        "        'Recall': metrics['Recall'],\n",
        "        'F1-Score': metrics['F1-Score'],\n",
        "        'Cross-Validation Mean': mean_cv,\n",
        "        'Cross-Validation Std': std_cv\n",
        "    })\n",
        "\n",
        "# Konversi daftar ke DataFrame\n",
        "summary_df = pd.DataFrame(rows)\n",
        "\n",
        "# Tampilkan hasil evaluasi\n",
        "print(summary_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4_9OwrsXZlz"
      },
      "source": [
        "Tulis hasil evaluasi algoritma yang digunakan, jika Anda menggunakan 2 algoritma, maka bandingkan hasilnya."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph9yIYDXEPuB"
      },
      "source": [
        "## **c. Tuning Model Klasifikasi (Optional)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Gunakan GridSearchCV, RandomizedSearchCV, atau metode lainnya untuk mencari kombinasi hyperparameter terbaik"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best KNN Params: {'metric': 'euclidean', 'n_neighbors': 4, 'weights': 'distance'}\n",
            "Best SVM Params: {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
            "Best NB Params: {'var_smoothing': np.float64(0.009699099521619943)}\n"
          ]
        }
      ],
      "source": [
        "# ================================\n",
        "# 1. Hyperparameter Tuning untuk KNN\n",
        "# ================================\n",
        "knn_params = {\n",
        "    'n_neighbors': range(1, 21),  # Jumlah tetangga dari 1 hingga 20\n",
        "    'weights': ['uniform', 'distance'],  # Cara memberi bobot tetangga\n",
        "    'metric': ['euclidean', 'manhattan']  # Jenis metrik jarak\n",
        "}\n",
        "\n",
        "knn_grid = GridSearchCV(KNeighborsClassifier(), knn_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "knn_grid.fit(X_train, y_train)\n",
        "best_knn = knn_grid.best_estimator_\n",
        "\n",
        "print(\"Best KNN Params:\", knn_grid.best_params_)\n",
        "\n",
        "# ================================\n",
        "# 2. Hyperparameter Tuning untuk SVM\n",
        "# ================================\n",
        "svm_params = {\n",
        "    'C': [0.1, 1, 10, 100],  # Regularisasi\n",
        "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],  # Jenis kernel\n",
        "    'gamma': ['scale', 'auto']  # Parameter gamma\n",
        "}\n",
        "\n",
        "svm_grid = GridSearchCV(SVC(), svm_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "svm_grid.fit(X_train, y_train)\n",
        "best_svm = svm_grid.best_estimator_\n",
        "\n",
        "print(\"Best SVM Params:\", svm_grid.best_params_)\n",
        "\n",
        "# ================================\n",
        "# 3. Hyperparameter Tuning untuk NaÃ¯ve Bayes (Menggunakan RandomizedSearchCV)\n",
        "# ================================\n",
        "nb_params = {\n",
        "    'var_smoothing': uniform(1e-9, 1e-2)  # Mencoba nilai dari 1e-9 hingga 1e-2\n",
        "}\n",
        "\n",
        "nb_random = RandomizedSearchCV(GaussianNB(), nb_params, cv=5, scoring='accuracy', n_iter=20, random_state=42, n_jobs=-1)\n",
        "nb_random.fit(X_train, y_train)\n",
        "best_nb = nb_random.best_estimator_\n",
        "\n",
        "print(\"Best NB Params:\", nb_random.best_params_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hE7pqlEPEYzI"
      },
      "source": [
        "## **d. Evaluasi Model Klasifikasi setelah Tuning (Optional)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feaPESoeN0zz"
      },
      "source": [
        "Berikut adalah rekomendasi tahapannya.\n",
        "1. Gunakan model dengan hyperparameter terbaik.\n",
        "2. Hitung ulang metrik evaluasi untuk melihat apakah ada peningkatan performa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                          Model  Accuracy  Precision    Recall  F1-Score  \\\n",
            "0     K-Nearest Neighbors (KNN)  1.000000   1.000000  1.000000  1.000000   \n",
            "1  Support Vector Machine (SVM)  1.000000   1.000000  1.000000  1.000000   \n",
            "2              Naive Bayes (NB)  0.998163   0.998226  0.998163  0.998178   \n",
            "\n",
            "   Cross-Validation Mean  Cross-Validation Std  \n",
            "0               0.998898              0.002026  \n",
            "1               0.997428              0.004600  \n",
            "2               0.993313              0.003953  \n"
          ]
        }
      ],
      "source": [
        "# Dictionary model terbaik setelah tuning\n",
        "best_models = {\n",
        "    'K-Nearest Neighbors (KNN)': best_knn,\n",
        "    'Support Vector Machine (SVM)': best_svm,\n",
        "    'Naive Bayes (NB)': best_nb\n",
        "}\n",
        "\n",
        "# Evaluasi ulang model setelah tuning\n",
        "tuned_results = {\n",
        "    model_name: evaluate_model(model, X_test, y_test)\n",
        "    for model_name, model in best_models.items()\n",
        "}\n",
        "\n",
        "# Evaluasi dengan Cross-Validation\n",
        "tuned_summary_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1-Score', 'Cross-Validation Mean', 'Cross-Validation Std'])\n",
        "\n",
        "tuned_rows = []\n",
        "for model_name, model in best_models.items():\n",
        "    mean_cv, std_cv = cross_validate_model(model, X, y, cv=5)\n",
        "\n",
        "    tuned_rows.append({\n",
        "        'Model': model_name,\n",
        "        'Accuracy': tuned_results[model_name]['Accuracy'],\n",
        "        'Precision': tuned_results[model_name]['Precision'],\n",
        "        'Recall': tuned_results[model_name]['Recall'],\n",
        "        'F1-Score': tuned_results[model_name]['F1-Score'],\n",
        "        'Cross-Validation Mean': mean_cv,\n",
        "        'Cross-Validation Std': std_cv\n",
        "    })\n",
        "\n",
        "# Konversi ke DataFrame\n",
        "tuned_summary_df = pd.DataFrame(tuned_rows)\n",
        "\n",
        "# Tampilkan hasil evaluasi setelah tuning\n",
        "print(tuned_summary_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRsOdm4uEgAW"
      },
      "source": [
        "## **e. Analisis Hasil Evaluasi Model Klasifikasi**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm3BhSi6N4_l"
      },
      "source": [
        "Berikut adalah **rekomendasi** tahapannya.\n",
        "\n",
        "1. Bandingkan hasil evaluasi sebelum dan setelah tuning (jika dilakukan).\n",
        "\n",
        "    | Model                          | Accuracy Sebelum | Accuracy Sesudah | Cross-Validation Mean Sebelum | Cross-Validation Mean Sesudah |\n",
        "    |--------------------------------|-----------------|-----------------|--------------------------------|--------------------------------|\n",
        "    | K-Nearest Neighbors (KNN)      | 0.9989          | 1.0000          | 0.9979                         | 0.9989                         |\n",
        "    | Support Vector Machine (SVM)   | 0.9978          | 1.0000          | 0.9969                         | 0.9974                         |\n",
        "    | Naive Bayes (NB)               | 0.9963          | 0.9982          | 0.9904                         | 0.9933                         |\n",
        "\n",
        "    ---\n",
        "2. Identifikasi kelemahan model, seperti:\\\n",
        "    **K-Nearest Neighbors (KNN)**\n",
        "   - Sebelum tuning, performanya sudah sangat tinggi (>99.8%).\n",
        "   - Setelah tuning, mencapai **100% accuracy**, tetapi bisa jadi **overfitting** terhadap dataset ini.\n",
        "   - Perlu diuji dengan **data baru (unseen data)** untuk memastikan tidak hanya hafal data training.\n",
        "\n",
        "    **Support Vector Machine (SVM)**\n",
        "   - Performa sebelum tuning **sangat baik** (99.78% accuracy).\n",
        "   - Setelah tuning, **100% accuracy**, yang juga menimbulkan potensi **overfitting**.\n",
        "   - Bisa diuji dengan **lebih banyak data** untuk validasi.\n",
        "\n",
        "    **Naive Bayes (NB)**\n",
        "   - Model ini mengalami **peningkatan kecil** setelah tuning.\n",
        "   - Accuracy sebelum tuning **99.63%**, setelah tuning **99.82%**.\n",
        "   - Meskipun lebih rendah dibanding KNN dan SVM, performanya tetap stabil tanpa indikasi overfitting yang kuat.\n",
        "3. Berikan rekomendasi tindakan lanjutan, seperti mengumpulkan data tambahan atau mencoba algoritma lain jika hasil belum memuaskan.\n",
        "\n",
        "    - **Cek dengan data baru:** Pastikan tidak ada overfitting dengan menguji model pada dataset lain.  \n",
        "    - **Lihat Confusion Matrix per kelas:** Apakah ada kelas dengan Precision/Recall rendah?  \n",
        "    - **Eksperimen dengan Ensemble Learning:** Coba kombinasi beberapa model untuk melihat apakah hasil lebih stabil.  \n",
        "    - **Gunakan lebih banyak data:** Jika dataset terbatas, coba perbanyak dengan augmentasi data atau pengumpulan lebih lanjut.  \n",
        "\n",
        "**Kesimpulan:** Fine-tuning meningkatkan performa, tetapi kita harus berhati-hati terhadap **overfitting**, terutama pada KNN dan SVM.  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "course-segmentation",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
